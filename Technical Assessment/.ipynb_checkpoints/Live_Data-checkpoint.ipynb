{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e88e330-dea0-41ca-97dc-bee841b34898",
   "metadata": {},
   "source": [
    "### Creating the database for live update prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10679620-db03-40a7-af98-866f72b3f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping latest data for Dry Maize (Product ID: 1)...\n",
      "Scraping latest data for White Irish Potatoes (Product ID: 163)...\n",
      "Scraping latest data for Dry Onions (Product ID: 158)...\n",
      "Scraping latest data for Watermelons (Product ID: 150)...\n",
      "Scraping latest data for Ripe Bananas (Product ID: 226)...\n",
      "Scraping latest data for Oranges (Product ID: 127)...\n",
      "Scraping latest data for Mangoes (Product ID: 147)...\n",
      "Scraping latest data for Kales (Product ID: 154)...\n",
      "Scraping latest data for Regular Spinach (Product ID: 161)...\n",
      "Scraping latest data for Cooking Bananas (Product ID: 255)...\n",
      "Data has been saved to SQLite database.\n",
      "Script completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# Product mapping\n",
    "products = {\n",
    "    1: \"Dry Maize\",\n",
    "    163: \"White Irish Potatoes\",\n",
    "    158: \"Dry Onions\",\n",
    "    150: \"Watermelons\",\n",
    "    226: \"Ripe Bananas\",\n",
    "    127: \"Oranges\",\n",
    "    147: \"Mangoes\",\n",
    "    154: \"Kales\",\n",
    "    161: \"Regular Spinach\",\n",
    "    255: \"Cooking Bananas\"\n",
    "}\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://amis.co.ke/site/market/0?product={product}&per_page=3000\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "all_data = []\n",
    "\n",
    "# Scrape the latest data for all products\n",
    "for product_id, product_name in products.items():\n",
    "    print(f\"Scraping latest data for {product_name} (Product ID: {product_id})...\")\n",
    "    url = base_url.format(product=product_id)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = bs(response.content, \"html.parser\")\n",
    "        table = soup.find(\"table\", class_=\"table table-bordered table-condensed\")\n",
    "        if table:\n",
    "            for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "                cells = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "                all_data.append(cells)\n",
    "        else:\n",
    "            print(f\"No table found for {url}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {url}, status code: {response.status_code}\")\n",
    "\n",
    "# Extracting column headers\n",
    "columns = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(all_data, columns=columns)\n",
    "\n",
    "df.columns =[\"Product\",\"Classification\",\"Grade\",\"Sex\",\"Market Area\",\"Wholesale Price\",\"Retail Price\",\"Quantity Supplied\",\"County Area\",\"Date\"]\n",
    "# Data cleaning\n",
    "df = df.drop(columns=[\"Classification\", \"Grade\", \"Sex\"])  # Drop unnecessary columns\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")  # Convert Date to datetime\n",
    "\n",
    "for col in [\"Wholesale Price\", \"Retail Price\", \"Quantity Supplied\"]:\n",
    "    df[col] = df[col].str.extract(r\"([\\d\\.]+)\", expand=False)  # Extract numeric values\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# Filter for specific counties\n",
    "counties = [\"Nairobi\", \"Nyandarua\", \"Nakuru\", \"Meru\", \"Kirinyaga\"]\n",
    "df = df[df[\"County Area\"].isin(counties)]\n",
    "\n",
    "df =df.dropna()\n",
    "\n",
    "db_path = r\"C:\\Users\\USER\\Markets.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "cursor =conn.cursor()\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Crops (\n",
    "    Product TEXT,\n",
    "    Market Area TEXT,\n",
    "    Wholesale Price REAL,\n",
    "    Retail Price REAL,\n",
    "    Quantity Supplied REAL,\n",
    "    County Area TEXT,\n",
    "    Date DATE\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Save DataFrame to SQLite table\n",
    "df.to_sql(\"Crops\", conn, if_exists=\"replace\", index=False)\n",
    "print(\"Data has been saved to SQLite database.\")\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "\n",
    "# Success message\n",
    "print(\"Script completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
